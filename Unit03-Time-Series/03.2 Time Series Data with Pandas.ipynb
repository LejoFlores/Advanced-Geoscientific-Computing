{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86f89a0",
   "metadata": {},
   "source": [
    "# 03.2 Say Hello to Pandas!\n",
    "\n",
    "![hello pandas!](../img/panda.jpg)\n",
    "\n",
    "The `Pandas` library is an immensely powerful tool for performing analysis on multidimensional (tabular) data in general, and time series data specifically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a15929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dataretrieval import nwis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "startDate = '1960-01-01'\n",
    "endDate = '2024-12-31'\n",
    "\n",
    "gage = '13185000' # Boise River Near Twin Springs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966e0a4",
   "metadata": {},
   "source": [
    "## 1. Datetime Objects in `Pandas`\n",
    "\n",
    "Because it is often used for analyzing time series data, `Pandas` is equipped with many of the same capabilities to work with `datetime` objects and, indeed, extends these capabilities in useful ways. For example, although a bit weird, if we wanted to create a time series of dates with an interval of every 2 weeks, beginning on the first Tuesday after our start date above, we can do so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db17c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDates_2W_Tues = pd.date_range(start=startDate, end=endDate, freq='2W-TUE')\n",
    "tsDates_2W_Tues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228eb47f",
   "metadata": {},
   "source": [
    "Perhaps a bit more useful, but if we wanted to create a time series that started at a particular day and time, but had fifteen minute intervals, we could do something like the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df650ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDates_15min = pd.date_range(start='2025-10-01 00:00:00', end='2025-10-02 00:00:00', freq='15min')\n",
    "tsDates_15min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb23a5",
   "metadata": {},
   "source": [
    "As we can see, the `date_range` function can help us create a time series at almost any __regular__ interval we want, using the `freq` flag, which is referred to as the offset alias. The following documentation provides a table of different offset aliases: https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases and their descriptions. Can you create a time series of objects that have a monthly interval that starts on the first of the month between `startDate` and `endDate`, as defined above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDates = pd.date_range(start=startDate, end=endDate, freq='MS')\n",
    "tsDates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d58e53",
   "metadata": {},
   "source": [
    "If we wanted a day of the month that was anything other than the start (`freq='MS'`) or end of the month (`freq='ME'`), we can use the function `pd.DateOffset()` to add a specific number of days to each element of our time series. For example, in land modeling we have vegetation leaf area index (LAI) changing on a daily basis, but we only have monthly mean estimates of LAI from satellites. We, therefore, often assume that the value for the monthly mean is valid on the 15th of the month and then interpolate for each day by computing a weighted average of the two nearest months (i.e., the value of LAI on March 16 is the sum of the LAI on March 15 times (30/31) and the LAI on April 15times (1/31)). So, we might need a time series that is monthly in nature, but where the day of the month is 15, instead of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ef130",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDates_midmonth = tsDates + pd.DateOffset(days=14)\n",
    "tsDates_midmonth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6d8a9",
   "metadata": {},
   "source": [
    "Before going further, let's examine the specific data type associated with `tsDates`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tsDates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be607553",
   "metadata": {},
   "source": [
    "So we can see that this is a special kind of object that is like a standard Python `datetime` object, but is particular to `pandas` indexes. A bit further down, we'll see why this is important. In the mean time, we can use some built-in attributes to access individual elements of the `tsDates` like the month and year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b46bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDates.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDates.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91c35a",
   "metadata": {},
   "source": [
    "If we look at the data type of `tsDates.year` we find that the datatype is still a `pandas` type object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3747b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tsDates.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f860e83",
   "metadata": {},
   "source": [
    "But, if we wanted to perform any mathematical operations on the years, we need to use the `.values` attribute to push the values of `tsDates.year` to a `numpy` array, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae28300",
   "metadata": {},
   "outputs": [],
   "source": [
    "WY = tsDates.year.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafdcb60",
   "metadata": {},
   "source": [
    "Verify that this is, indeed a numpy array: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(WY)\n",
    "WY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776acf8e",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Run the following code, examine the output and explain what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8170a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WY[tsDates.month > 9] = WY[tsDates.month > 9] + 1\n",
    "WY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937dbed",
   "metadata": {},
   "source": [
    "## 2. DataFrames in Pandas\n",
    "\n",
    "Beyond __creating__ time series with Pandas, the primary way that we use Pandas is to deal with tabular data, of which time series data is a special case. For example, let's use the `dataretrieval` library again to get discharge data for the Boise River between our start and end dates. Specifically, let's look at what the `dataretrieval` library returns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiverQ = nwis.get_dv(sites=gage, parameterCd='00060', start=startDate, end=endDate)[0]\n",
    "type(BoiseRiverQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d25d2c",
   "metadata": {},
   "source": [
    "Let's look at what is inside this `DataFrame`. What does the following look like, or remind you of? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiverQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiverQ.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiverQ.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92c7b1",
   "metadata": {},
   "source": [
    "### `.groupby()`: The Most Powerful Operator In All of Python and Pandas? \n",
    "\n",
    "In the following code below, we use an operator on a `Pandas` dataframe to get the annual maximum value of daily discharge in the Boise River over the period from 1960 to 2024, as well as the unique values of the years. The `.groupby()` operator as used below, effectively tells `Pandas`: \"group the column '00060_Mean' by the years in the index of the dataframe (the date), and then for each of those groups, give me the maximum.\" Ordinarily we would have resorted to writing `for` loops, looping over all years and then getting the maximum value within each year. No need to do so with `Pandas` and this actually reveals something pretty intriguing about modern computation and analysis of large datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1914e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiverQ['00060_Mean'].groupby(BoiseRiverQ.index.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a26aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiver_AnnMaxQ = BoiseRiverQ['00060_Mean'].groupby(BoiseRiverQ.index.year).max()\n",
    "BoiseRiver_year = np.unique(BoiseRiverQ.index.year.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(BoiseRiver_year, BoiseRiver_AnnMaxQ, 'kd')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Annual Maximum Flow [ft${}^3$/s]')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0751307",
   "metadata": {},
   "source": [
    "### Challenge: Mean Monthly Flow\n",
    "\n",
    "Can you use the `groupby()` function as show below, but instead, use it to compute and plot the mean monthly flow in the Boise River? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoiseRiverQ['00060_Mean'].groupby([BoiseRiverQ.index.year,BoiseRiverQ.index.month]).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79877279",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
